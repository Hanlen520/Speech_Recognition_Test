# Speech_Recognition_Test
# 中文语音识别
# 1、项目运行环境
Windows7x64  
Pycharm 2018.2.4 
Python 3.6.2  
独立显卡 GTX1050Ti
# 2、项目运行所需的库文件
Numpy（用于矩阵运算）  
tensorflow-gpu（GPU版本有助于加快训练速度）  
scipy.io.wavfile（用于读取音频文件）  
python_speech_features（用于获取音频的梅尔倒普系数）
# 3、项目训练所需数据
下载地址：http://www.openslr.org/18/  
下载文件：data_thchs30.tgz 
# 4、项目构建思路
1）将样本数据读入内存（包括音频数据和标签数据）  
2）建立批次获取样本的函数  
3）将语音数据转换成梅尔倒频谱系数（MFCC数据）（将时域数据转换成频域数据）  
4）将MFCC转换成训练格式数据时间列和频率特征系数行的矩阵  
5）文本转换成向量  
6）用于读取文件操作  
7）对齐该批次的音频数据  
8）将文本数据转换成稀疏矩阵（也就是密集矩阵转换成稀疏矩阵）  
9）字向量转换成文字  
10）构建网络结构进行模型训练：BiRNN_model    
11）调用cpu函数  
12）读取待测试数据（包括音频数据和标签数据）  
13）将数据代入已训练好的模型中  
14）打印识别信息对比识别效果  
# 5、项目运行方法
配置conf目录下的conf.ini中的各项，主要是配置训练和测试所需的数据文件的路径，训练模型和log文件保存路径  
打开Pycharm新创建一个项目，将项目所需Python文件添加进去  
运行train.py文件对模型进行训练  
运行test.py文件对训练好的模型进行测试验证    
# 6、注意事项
以上网址下载的训练数据并不完整，只有音频文件，没有标签数据，为了方便进行训练和检测识别效果，本人已从其他地方找到了对应的标签数据（doc.rar）  
由于数据文件量较大，训练时间会很长，以本人的家用电脑配置（AMD FX-Series FX-8300 八核 12GB内存 GTX1050Ti显卡）全部训练下来大概用了五天的时间，如果想尽快看到训练效果，可缩减训练数据量，但训练出的模型泛化能力会较差，如想达到实际应用的效果请选择服务器级别的机器或分布式系统  
